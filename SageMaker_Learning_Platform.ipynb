{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627e905e",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Learning Platform - Interactive Tutorial\n",
    "\n",
    "## üöÄ Comprehensive Guide to Building and Using SageMaker Learning Resources\n",
    "\n",
    "Welcome to this interactive notebook that demonstrates how to use the Amazon SageMaker Learning Platform. This notebook contains all the resources, links, and practical examples you need to master SageMaker.\n",
    "\n",
    "### üìã What You'll Learn:\n",
    "- How to access and use the downloadable resources (PDF, PPT)\n",
    "- Interactive Google Colab notebooks for hands-on practice\n",
    "- Complete SageMaker development workflow\n",
    "- Best practices and real-world examples\n",
    "\n",
    "### üîó Available Resources:\n",
    "1. **Developer PDF**: [SageMaker_doc.pdf](https://raw.githubusercontent.com/07Sushant/dump/main/SageMaker_doc.pdf)\n",
    "2. **Workflow PPT**: [SageMaker_PPT.pptx](https://raw.githubusercontent.com/07Sushant/dump/main/SageMaker_PPT.pptx)\n",
    "3. **Getting Started Notebook**: [Colab Link 1](https://colab.research.google.com/drive/1k6DfzXKMih7BvzJ5OXFU_WEfQfI7-RC_?usp=sharing)\n",
    "4. **Model Training Notebook**: [Colab Link 2](https://colab.research.google.com/drive/1F0L2gTWSrZQH0BwIaRrmeS2tE500A-CL?usp=sharing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8414e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SageMaker specific imports\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Display versions\n",
    "print(\"Python Libraries Setup Complete!\")\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")\n",
    "print(f\"Boto3 Version: {boto3.__version__}\")\n",
    "print(f\"Current Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Basic AWS Configuration Check\n",
    "try:\n",
    "    session = boto3.Session()\n",
    "    region = session.region_name or 'us-east-1'\n",
    "    print(f\"AWS Region: {region}\")\n",
    "except Exception as e:\n",
    "    print(\"Note: Configure AWS credentials for full functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38c678",
   "metadata": {},
   "source": [
    "## üèóÔ∏è SageMaker Architecture Overview\n",
    "\n",
    "Amazon SageMaker is a fully managed machine learning service that enables developers and data scientists to build, train, and deploy ML models at scale.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "#### 1. **SageMaker Studio**\n",
    "- Integrated development environment for ML\n",
    "- Jupyter notebook interface\n",
    "- Visual workflow designer\n",
    "\n",
    "#### 2. **SageMaker Notebooks**\n",
    "- Pre-configured Jupyter notebooks\n",
    "- Built-in algorithms and frameworks\n",
    "- Collaborative development\n",
    "\n",
    "#### 3. **SageMaker Training**\n",
    "- Distributed training capabilities\n",
    "- Automatic model tuning\n",
    "- Built-in algorithms\n",
    "\n",
    "#### 4. **SageMaker Hosting**\n",
    "- Real-time inference endpoints\n",
    "- Batch transform jobs\n",
    "- Multi-model endpoints\n",
    "\n",
    "#### 5. **SageMaker Pipelines**\n",
    "- ML workflow orchestration\n",
    "- CI/CD for ML models\n",
    "- Automated retraining\n",
    "\n",
    "### üìä ML Lifecycle with SageMaker:\n",
    "\n",
    "```\n",
    "Data Preparation ‚Üí Model Training ‚Üí Model Validation ‚Üí Model Deployment ‚Üí Monitoring\n",
    "      ‚Üì                ‚Üì               ‚Üì                ‚Üì              ‚Üì\n",
    "  Ground Truth    Training Jobs    Model Registry   Endpoints    Model Monitor\n",
    "  Data Wrangler   Hyperparameter   A/B Testing     Batch Jobs   Data Quality\n",
    "  Processing Jobs    Tuning        Model Cards     Multi-Model   Model Drift\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Session Setup\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get the execution role (when running on SageMaker)\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "    print(f\"SageMaker Execution Role: {role}\")\n",
    "except:\n",
    "    # For local development, you can specify your role ARN\n",
    "    role = \"arn:aws:iam::YOUR_ACCOUNT:role/service-role/AmazonSageMaker-ExecutionRole\"\n",
    "    print(\"Using local development role\")\n",
    "\n",
    "# Get default bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Default S3 Bucket: {bucket}\")\n",
    "\n",
    "# Get region\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(f\"AWS Region: {region}\")\n",
    "\n",
    "# Display SageMaker session information\n",
    "print(\"\\n=== SageMaker Session Information ===\")\n",
    "print(f\"SageMaker Session: {sagemaker_session}\")\n",
    "print(f\"Boto Session Region: {sagemaker_session.boto_region_name}\")\n",
    "print(f\"Default Bucket: {sagemaker_session.default_bucket()}\")\n",
    "\n",
    "# Create S3 prefix for our experiments\n",
    "prefix = 'sagemaker-learning-platform'\n",
    "print(f\"S3 Prefix: {prefix}\")\n",
    "\n",
    "# Test S3 connectivity\n",
    "try:\n",
    "    s3_client = sagemaker_session.boto_session.client('s3')\n",
    "    buckets = s3_client.list_buckets()\n",
    "    print(f\"‚úÖ S3 Connection Successful - Found {len(buckets['Buckets'])} buckets\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå S3 Connection Error: {e}\")\n",
    "\n",
    "print(\"\\nüéâ SageMaker environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5e875",
   "metadata": {},
   "source": [
    "## üìä Data Preparation and Processing\n",
    "\n",
    "Data preparation is crucial for successful machine learning projects. SageMaker provides several tools and services for data preparation:\n",
    "\n",
    "### Available Tools:\n",
    "- **SageMaker Data Wrangler**: Visual data preparation tool\n",
    "- **SageMaker Processing Jobs**: Scalable data processing\n",
    "- **SageMaker Ground Truth**: Data labeling service\n",
    "- **Built-in Algorithms**: Pre-processing capabilities\n",
    "\n",
    "### Data Processing Workflow:\n",
    "1. **Data Ingestion**: Load data from various sources\n",
    "2. **Data Exploration**: Understand data characteristics\n",
    "3. **Data Cleaning**: Handle missing values, outliers\n",
    "4. **Feature Engineering**: Create meaningful features\n",
    "5. **Data Splitting**: Train/validation/test sets\n",
    "6. **Data Upload**: Store processed data in S3\n",
    "\n",
    "Let's walk through a practical example using a sample dataset:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data Creation and Preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a sample dataset for demonstration\n",
    "print(\"Creating sample dataset...\")\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    n_redundant=2,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create feature names\n",
    "feature_names = [f'feature_{i+1}' for i in range(X.shape[1])]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Features: {list(df.columns[:-1])}\")\n",
    "print(f\"Target Distribution:\\n{df['target'].value_counts()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing Values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Visualize target distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "df['target'].value_counts().plot(kind='bar')\n",
    "plt.title('Target Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Correlation heatmap of first 5 features\n",
    "correlation_matrix = df[feature_names[:5]].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix (First 5 Features)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample dataset created and explored successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
